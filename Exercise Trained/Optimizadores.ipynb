{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef0753f-f3d9-4c2f-8661-6166d0c8ddd3",
   "metadata": {},
   "source": [
    "<img src=\"../img/Logo.png\" width=\"200\">\n",
    "\n",
    "# Aprendizaje por Im谩genes\n",
    "## Optimizadores\n",
    "\n",
    "### Profesor: Jorge Calvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c48a02-3314-4d51-bbd2-b9b8e84de390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e51c2c3-d839-4f64-bc64-6aa292eb81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset MNIST y preprocesar las im谩genes\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Reestructuramos y normalizamos (las im谩genes se escalan a [0, 1])\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "\n",
    "# Visualizar algunas im谩genes de entrenamiento\n",
    "fig, axs = plt.subplots(2, 4, figsize=(8, 4))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.set_title(f\"Label: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e098d51e-7f86-4678-a315-e32b5e23ef21",
   "metadata": {},
   "source": [
    "### Explicaci贸n de Optimizadores\n",
    "\n",
    "#### AdaGrad:\n",
    "* Ventaja: Adapta bien la tasa de aprendizaje para par谩metros con gradientes escasos (煤til cuando algunas caracter铆sticas visuales aparecen con menor frecuencia).\n",
    "* Desventaja: La tasa de aprendizaje puede disminuir demasiado con el tiempo.\n",
    "\n",
    "#### RMSProp:\n",
    "\n",
    "* Ventaja: Mantiene una tasa de aprendizaje estable mediante un promedio m贸vil de los gradientes, lo que es beneficioso en escenarios con funciones de p茅rdida muy variables, como es frecuente en redes convolucionales.\n",
    "* Desventaja: Requiere ajustar el hiperpar谩metro de decaimiento ().\n",
    "\n",
    "#### Adam:\n",
    "\n",
    "* Ventaja: Combina la estabilidad de RMSProp y la eficiencia del momentum, lo que resulta en una convergencia r谩pida y robusta en una amplia variedad de problemas de visi贸n artificial.\n",
    "* Desventaja: Aunque suele funcionar bien en la mayor铆a de los casos, en algunos escenarios espec铆ficos puede requerir ajustes finos de la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef4297-ab02-4c3f-b68f-75513fac2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci贸n para construir la arquitectura del modelo\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Diccionario con los optimizadores a comparar\n",
    "optimizers_dict = {\n",
    "    \"Adam\": optimizers.Adam(learning_rate=0.001),\n",
    "    \"AdaGrad\": optimizers.Adagrad(learning_rate=0.001),\n",
    "    \"RMSProp\": optimizers.RMSprop(learning_rate=0.001)\n",
    "}\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e2468-e98c-4e70-bfd6-f37d4096dcaa",
   "metadata": {},
   "source": [
    "# F贸rmulas de Cross Entropy y Sparse Categorical Cross Entropy\r\n",
    "\r\n",
    "### Categorical Cross Entropy\r\n",
    "\r\n",
    "La funci贸n de p茅rdida de **Categorical Cross Entropy** se define como:\r\n",
    "\r\n",
    "$$\r\n",
    "L = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)\r\n",
    "$$\n",
    "\n",
    "donde:\r\n",
    "- \\( C \\) es el n煤mero\n",
    " clases.\r\n",
    "- \\( y_i \\) es la etiqueta verdadera para la clase \\( i \\) (en formato one-hot, es decir, \\( y_i = 1 \\) para la clase correcta y \\( 0 \\) para\n",
    "s dem谩s).\r\n",
    "- \\( \\hat{y}_i \\) es la probabilidad predicha para la c\n",
    "\n",
    "#### Ventajas:\n",
    "\n",
    "Directamente optimizada para clasificaci贸n.\n",
    "Penaliza fuertemente las predicciones incorrectas.\n",
    "La salida softmax genera una distribuci贸n de probabilidad que se alinea con la funci贸n de p茅rdida.\n",
    "\n",
    "* Aplicaci贸n en MNIST:\n",
    "Es la funci贸n de p茅rdida m谩s utilizada en tareas de clasificaci贸n multiclase, ya que proporciona un gradiente bien definido para la actualizaci贸n de los pesos.lase \\( i \\).\r\n",
    "\r\n",
    "### Sparse Categorical Cross Entropy\r\n",
    "\r\n",
    "La funci贸n de p茅rdida de **Sparse Categorical Cross Entropy** se define como:\r\n",
    "\r\n",
    "$$\r\n",
    "L = -\\log\\left(\\hat{y}_{y_{\\text{true}}}\\right)\r\n",
    "$$\r\n",
    "\r\n",
    "donde:\r\n",
    "- \\( \\hat{y}_{y_{\\text{true}}} \\) es la probabilidad predicha para la clase correcta.\r\n",
    "- Las etiquetas verdaderas se representan como enteros (por ejemplo, \\( 3 \\) en lugar de \\(\n",
    "\n",
    "#### Ventajas:\n",
    "\n",
    "Menos consumo de memoria y computacionalmente m谩s eficiente cuando se tienen muchas clases.\n",
    "Evita el paso de transformaci贸n a one-hot, lo cual simplifica el preprocesamiento.\n",
    "\n",
    "* Aplicaci贸n en MNIST:\n",
    "Debido a que MNIST tiene 10 clases y las etiquetas pueden representarse f谩cilmente como enteros, es com煤n usar sparse categorical cross entropy para simplificar el c贸digo y la preparaci贸n de datos.[0,0,0,1,0,0,0,0,0,0]\\)).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961f943-e673-4753-b662-29aff21aceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenaremos los historiales de entrenamiento para cada optimizador\n",
    "histories = {}\n",
    "\n",
    "for opt_name, opt in optimizers_dict.items():\n",
    "    print(f\"Entrenando con el optimizador: {opt_name}\")\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='sparse_categorical_crossentropy',  # Utilizamos sparse ya que las etiquetas son enteros\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1)\n",
    "    histories[opt_name] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fae24-9aaf-4ed4-bc45-edc441e4b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci贸n de las curvas de entrenamiento y validaci贸n para precisi贸n y p茅rdida\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Curva de precisi贸n\n",
    "plt.subplot(1, 2, 1)\n",
    "for opt_name, history in histories.items():\n",
    "    plt.plot(history.history['accuracy'], label=f'{opt_name} - Entrenamiento')\n",
    "    plt.plot(history.history['val_accuracy'], label=f'{opt_name} - Validaci贸n', linestyle='--')\n",
    "plt.title('Evoluci贸n de la Precisi贸n')\n",
    "plt.xlabel('poca')\n",
    "plt.ylabel('Precisi贸n')\n",
    "plt.legend()\n",
    "\n",
    "# Curva de p茅rdida\n",
    "plt.subplot(1, 2, 2)\n",
    "for opt_name, history in histories.items():\n",
    "    plt.plot(history.history['loss'], label=f'{opt_name} - Entrenamiento')\n",
    "    plt.plot(history.history['val_loss'], label=f'{opt_name} - Validaci贸n', linestyle='--')\n",
    "plt.title('Evoluci贸n de la P茅rdida')\n",
    "plt.xlabel('poca')\n",
    "plt.ylabel('P茅rdida')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd733cc2-ce75-469e-bb3c-22a7eca2d100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
