{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ataque FGSM (Fast Gradient Sign Method)\n",
    "\n",
    "### Seguridad en redes neuronales convolucionales\n",
    "#### Autor: Jorge Calvo Martín\n",
    "\n",
    "* Este ataque consiste en generar ejemplos adversarios, casi indistinguibles por el ojo humano, que sean capaces de confundir o engañar a un modelo de Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. ¿Qué es un Ataque Adversarial?\n",
    "\n",
    "Un ataque adversarial consiste en realizar pequeñas modificaciones en una imagen (o cualquier otro dato de entrada) de forma que estas alteraciones, casi imperceptibles para el ojo humano, hagan que un modelo de clasificación cometa errores. Es decir, se busca \"engañar\" al modelo para que produzca una predicción incorrecta.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Principio del FGSM\n",
    "\n",
    "La idea central del FGSM es encontrar una pequeña perturbación que, sumada a la imagen original, aumente la función de pérdida del modelo. De esta forma, el modelo se confunde y falla en su clasificación.\n",
    "\n",
    "La fórmula para generar una imagen adversarial es:\n",
    "\n",
    "$\n",
    "\\mathbf{X}_{adv} = \\mathbf{X} + \\epsilon \\cdot \\operatorname{sign} \\Big( \\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) \\Big)\n",
    "$\n",
    "\n",
    "donde:\n",
    "- $\\mathbf{X}$ es la imagen original.\n",
    "- \\(y\\) es la etiqueta correcta de la imagen.\n",
    "- $J(\\theta, \\mathbf{X}, y)$ es la función de pérdida del modelo, con parámetros $\\theta$.\n",
    "- $\\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y)$ es el gradiente de la pérdida respecto a la imagen.\n",
    "- $\\operatorname{sign}(\\cdot)$ toma el signo de cada componente del gradiente.\n",
    "- $\\epsilon$ es un pequeño factor que controla la magnitud de la perturbación.\n",
    "\n",
    "**Interpretación:**  \n",
    "El término $\\operatorname{sign}\\Big( \\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) \\Big)$ indica la dirección en la que cada píxel debe modificarse para incrementar la pérdida. Al multiplicar por $\\epsilon$, aseguramos que la perturbación sea pequeña, y al sumarla a $\\mathbf{X}$, obtenemos la imagen adversarial $\\mathbf{X}_{adv}$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Proceso Paso a Paso del Ataque FGSM\n",
    "\n",
    "1. **Obtener la imagen original $\\mathbf{X}$ y su etiqueta $y$:**  \n",
    "   Se parte de la imagen que queremos atacar.\n",
    "\n",
    "2. **Calcular la función de pérdida $J(\\theta, \\mathbf{X}, y)$:**  \n",
    "   Se utiliza la función de pérdida del modelo, que compara la predicción con la etiqueta correcta.\n",
    "\n",
    "3. **Calcular el gradiente:**  \n",
    "   Se realiza backpropagation para obtener el gradiente de la pérdida respecto a la imagen:  \n",
    "   $\\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y)$.\n",
    "\n",
    "4. **Generar la perturbación:**  \n",
    "   Se obtiene la dirección de cambio mediante $\\operatorname{sign}\\Big( \\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) \\Big)$ y se multiplica por $\\epsilon$.\n",
    "\n",
    "5. **Crear la imagen adversarial:**  \n",
    "   La imagen modificada se calcula como:  \n",
    "   $\\mathbf{X}_{adv} = \\mathbf{X} + \\epsilon \\cdot \\operatorname{sign}\\Big( \\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) \\Big)$.\n",
    "\n",
    "6. **Evaluar el modelo con $\\mathbf{X}_{adv}$:**  \n",
    "   Al introducir la imagen adversarial en el modelo, se observa que la predicción cambia, generalmente de forma incorrecta.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Ejemplo Matemático Sencillo\n",
    "\n",
    "Supongamos que tenemos una imagen representada como un vector $\\mathbf{X} = [x_1, x_2, \\ldots, x_n]$ y queremos atacar esta imagen. Imaginemos que para un modelo concreto, el gradiente de la pérdida con respecto a la imagen es:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) = [0.2, -0.4, 0.1, \\ldots, 0.3]\n",
    "$$\n",
    "\n",
    "Aplicamos la función de signo a este gradiente:\n",
    "\n",
    "$$\n",
    "\\operatorname{sign} \\Big( \\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) \\Big) = [1, -1, 1, \\ldots, 1]\n",
    "$$\n",
    "\n",
    "Si elegimos un valor pequeño, por ejemplo, $\\epsilon = 0.01$, la perturbación que añadiremos será:\n",
    "\n",
    "$$\n",
    "\\epsilon \\cdot \\operatorname{sign} \\Big( \\nabla_{\\mathbf{X}} J(\\theta, \\mathbf{X}, y) \\Big) = [0.01, -0.01, 0.01, \\ldots, 0.01]\n",
    "$$\n",
    "\n",
    "La imagen adversarial se obtiene sumando esta perturbación a la imagen original:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}_{adv} = \\mathbf{X} + [0.01, -0.01, 0.01, \\ldots, 0.01]\n",
    "$$\n",
    "\n",
    "Incluso si esta suma apenas modifica los valores originales, la dirección de la perturbación puede hacer que el modelo confunda la imagen y realice una clasificación errónea.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conclusión\n",
    "\n",
    "El método FGSM demuestra cómo, mediante pequeños cambios calculados en la entrada, se puede engañar a un modelo de clasificación. A pesar de que la perturbación es casi imperceptible para el ojo humano, puede ser suficiente para que el modelo cometa un error, lo que subraya la importancia de desarrollar sistemas robustos frente a ataques adversariales.\n",
    "\n",
    "Este ejemplo y explicación deberían ayudarte a entender de forma práctica cómo se realiza un ataque adversarial utilizando FGSM.\n",
    "\n",
    "---\n",
    "\n",
    "*Puedes incluir este contenido en una celda Markdown de tu notebook para tener la explicación completa y el ejemplo matemático a la vista.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando entrenamos un modelo tenemos que pasarle unas entradas, que normalmente se encuentran acotadas dentro de un dominio. Por ejemplo, los píxeles de las imágenes toman valores enteros entre 0 y 255. Por tanto, nuestra red se debería comportar de la misma forma si introducimos los píxeles con intensidades X = [21, 34, 128, 11] y Xs = [21.001, 34.001, 128.001, 11.001]. La realidad es que no es así. Como vimos antes en una red sencilla se realiza la operación de la Figura 3. Eliminaremos algunos términos para facilitar la explicación, dejando la expresión de la siguiente forma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\hat{Y} = X * W'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos nuestra entrada Xs es el resultado de sumar X + S, siendo S = [0.001, 0.001, 0.001, 0.001]. Por tanto, si introducimos como entrada Xs la salida vendrá determinada por la siguiente ecuación: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\hat{Y_S} = X * W + S *W'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta ecuación podemos ver que si W es positivo y su dimensión es muy grande (recordad que en casos reales estamos hablando de millones de parámetros) podríamos producir un cambio muy grande en la salida haciendo un cambio muy pequeño en la entrada. La amplificación de la salida viene dada por la fórmula E*N*M, siendo E = ||S||, N el número de dimensiones de W y M el valor medio de W. El ataque FSGM modifica la imagen de entrada siguiendo la fórmula siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'X_S = X + S'))\n",
    "display(Math(r'S = \\epsilon * sign(\\nabla J(X,Y))'))\n",
    "display(Math(r'J = Función\\ de\\ coste'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podéis ver estamos calculando el signo de los gradientes de la función de coste con respecto a la imagen de entrada y después lo estamos multiplicando por un valor E. El signo de los gradientes nos proporciona la dirección aproximada de maximización de la función de coste y con E regulamos la cantidad de pérdida. Por tanto, estamos modificando la imagen de forma que maximicemos la probabilidad de que la red falle. Sé que puede sonar un poco complicado, por ello vamos a intentar verlo gráficamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecir una foto usando el modelo MobilNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilNet=tf.keras.applications.MobileNetV2(include_top=True,weights='imagenet')\n",
    "\n",
    "# ImageNet labels\n",
    "decode_predictions = tf.keras.applications.mobilenet_v2.decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    img = img[None, ...]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_Net(img):\n",
    "    #Cargamos la foto con un tamaño ya establecido que nos pide el modelo (224,224)\n",
    "  \n",
    "    img=process_image(img)\n",
    "    \n",
    "    #Se lo pasamos al modelo\n",
    "    y=mobilNet.predict(img)\n",
    "    \n",
    "    #print(y.shape)\n",
    "    #devuelve un valor por cada clase que predice (1000 clases), el llamado one-hot-encoding\n",
    "    \n",
    "    #Utilizamos decode_predicctions para asociar el valor a cada clase\n",
    "    return img,y,decode_predictions(y, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_raw = tf.io.read_file(\"examples/beer.jpg\")\n",
    "image = tf.image.decode_image(image_raw)\n",
    "img,y,prediction=predecir_Net(image)\n",
    "#img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saco la posición maxima del vector de predicción, el cual me dará el número de la clase.\n",
    "max_index_row = np.argmax(y, axis=1)\n",
    "max_index_row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(process_image(image)[0]*0.5+0.5)\n",
    "plt.title('Clase: {} {} : {:.2f}% Eficacia'.format(max_index_row[0],prediction[1], prediction[2]*100))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convierto las etiquestas en un vector  One hot encoding\n",
    "label=tf.one_hot(max_index_row,y.shape[-1])\n",
    "label = tf.reshape(label, (1, y.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar Imagen Adversaria usando FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(process_image(image).shape)\n",
    "#Generamos la función de coste\n",
    "loss_function=tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la imagen adversaria\n",
    "def create_adversary(x,y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        y_hat = mobilNet(x)\n",
    "        loss = loss_function(y, y_hat)\n",
    "        #print(loss)\n",
    "\n",
    "      # Get the gradients of the loss w.r.t to the input image.\n",
    "    gradient = tape.gradient(loss, x)\n",
    "      # Get the sign of the gradients to create the perturbation\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_grad = create_adversary(process_image(image),label)\n",
    "plt.imshow(np.reshape(signed_grad,(224,224,3)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos la formula\n",
    "display(Math(r'adv_{img}= X + \\epsilon * sign(\\nabla J(X,Y))'))\n",
    "adv_img = process_image(image) + 0.01*signed_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mobilNet.predict(adv_img)\n",
    "prediction_adv=decode_predictions(y, top=1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(adv_img[0]*0.5+0.5)\n",
    "plt.title('{} : {:.2f}% Eficacia'.format(prediction_adv[1], prediction_adv[2]*100))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
