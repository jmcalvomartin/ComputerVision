{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d32254c-16b6-47b2-b484-41c03640e1ea",
   "metadata": {},
   "source": [
    "<img src=\"../img/UAX.png\" width=\"300\">\n",
    "\n",
    "# AutoEncoder - Creación de imágenes\n",
    "\n",
    "### Profesor: Jorge Calvo\n",
    "\n",
    "Los Autoencoders son una clase especial de redes neuronales que se utilizan para la compresión y reconstrucción de datos. Su objetivo principal es aprender a representar eficientemente la información de entrada en una capa oculta y luego reconstruirla con la menor pérdida de calidad posible.\n",
    "\n",
    "Imagina que tienes una imagen de un gato y quieres comprimirla en una representación más pequeña y simple, pero aún así quieres poder reconstruir la imagen original. Aquí es donde entran en juego los Autoencoders.\n",
    "\n",
    "El Autoencoder consta de dos partes principales: el codificador y el decodificador. El codificador se encarga de comprimir los datos de entrada en una representación de menor dimensionalidad, mientras que el decodificador se encarga de reconstruir los datos originales a partir de esta representación comprimida.\n",
    "\n",
    "El proceso de entrenamiento de un Autoencoder implica alimentar el modelo con los datos de entrada, y el objetivo es minimizar la diferencia entre la entrada original y la salida reconstruida. A medida que el modelo se entrena, el codificador aprende a capturar las características más importantes de los datos de entrada y el decodificador aprende a utilizar esas características para reconstruir la información original.\n",
    "\n",
    "<img src=\"https://github.com/jmcalvomartin/python/blob/master/img/autoencoder.png?raw=True\" width=\"800\">\n",
    "\n",
    "\n",
    "Referencia: https://www.europeanvalley.es/noticias/el-espacio-latente-en-la-ia/\n",
    "\n",
    "### Ejercicio usando el dataset MNIST\n",
    "El dataset MNIST es uno de los conjuntos de datos más populares en el campo del aprendizaje automático y la visión por computadora. MNIST representa el conjunto de dígitos escritos a mano del 0 al 9, donde cada imagen es una representación de 28x28 píxeles en escala de grises.\n",
    "\n",
    "Imagina que tienes una hoja de papel y un lápiz. Ahora, trata de escribir un número del 0 al 9 en la hoja. Después de escribir cada número, escaneas la hoja y obtienes una imagen digital. Esa imagen digital se parece mucho a las imágenes en el conjunto de datos MNIST.\n",
    "\n",
    "Este conjunto de datos es ampliamente utilizado para entrenar y probar algoritmos de clasificación, ya que proporciona una buena representación de los desafíos comunes en la clasificación de imágenes, como la variabilidad en la escritura a mano, la calidad de la imagen y la resolución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3f7b9-8e86-4ce2-b9cb-fda265de6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers, models, losses, backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from keras.models import Model, load_model\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Solo mostrar errores y advertencias críticas\n",
    "\n",
    "# Configurar el crecimiento de memoria en la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "print(\"GPUs disponibles: \", tf.config.experimental.list_physical_devices('GPU'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5399f3b-427a-493a-97c4-8da578b0a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar el conjunto de datos MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Visualizar algunas imágenes de entrenamiento\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.set_title(f\"Label: {y_train[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0affdb-12a0-4bcd-8bd0-d2f0fcd5408b",
   "metadata": {},
   "source": [
    "### Autoencoders con capas planas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6564f-14bc-4ad1-a970-45f6d4bbd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizar los datos\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Definir la arquitectura del Autoencoder\n",
    "encoder_input = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Flatten()(encoder_input)\n",
    "x = tf.keras.layers.Dense(784, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "encoded = tf.keras.layers.Dense(3, activation='relu')(x)\n",
    "\n",
    "decoded = tf.keras.layers.Dense(#valor, activation='relu')(encoded)\n",
    "decoded = tf.keras.layers.Dense(#valor, activation='softmax')(decoded)\n",
    "decoded = tf.keras.layers.Reshape((28, 28, 1))(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5e324-28fc-485b-ada5-37f6c5c5a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo Autoencoder\n",
    "autoencoder_plano = tf.keras.Model(encoder_input, decoded)\n",
    "\n",
    "plot_model(autoencoder_plano, to_file='./red_plana.png', show_shapes=True, show_layer_names=True, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d01710-bfa0-4bed-be74-619042d9808f",
   "metadata": {},
   "source": [
    "### Autoencoders con Capas convolucionales\n",
    "La operación de UpSampling consiste en duplicar los valores de una imagen o volumen en ambas dimensiones (alto y ancho). Esto se hace para aumentar el tamaño de la imagen o volumen sin perder información importante.\n",
    "\n",
    "En TensorFlow, la capa de UpSampling se implementa mediante la clase UpSampling2D para imágenes 2D y UpSampling3D para volúmenes 3D. Ambas capas toman un parámetro size que especifica la escala de aumento en cada dimensión. Por ejemplo, si size es igual a 2, la imagen o volumen se duplicará en ambas dimensiones.\n",
    "\n",
    "Es importante tener en cuenta que la capa de UpSampling no agrega información nueva, sino que repite los valores existentes. Por lo tanto, es esencial que la información relevante ya esté presente en las capas anteriores de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b949304-fff9-4856-bdad-e58f82e0b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalizar los datos\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Definir la arquitectura del Autoencoder\n",
    "encoder_input = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Conv2D(32,(3,3), padding=\"same\", name=\"Cov1\")(encoder_input)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(64,(3,3), padding=\"same\", name=\"Cov2\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128)(x)\n",
    "x = tf.keras.layers.Dense(32)(x)\n",
    "\n",
    "encoded = tf.keras.layers.Dense(3, name=\"BottleNeck\")(x)\n",
    "\n",
    "decoded = tf.keras.layers.Dense(#valor)(encoded)\n",
    "decoded = tf.keras.layers.Dense(#valor)(decoded)\n",
    "decoded = tf.keras.layers.Reshape((#valor))(decoded)\n",
    "decoded = tf.keras.layers.Conv2DTranspose(1, (3, 3), padding='same', name=\"Cov2.T\")(decoded)\n",
    "decoded = tf.keras.layers.UpSampling2D((2, 2))(decoded)\n",
    "decoded = tf.keras.layers.Conv2DTranspose(1, (3, 3), padding='same',name=\"Cov1.T\",activation=\"sigmoid\")(decoded)\n",
    "decoded = tf.keras.layers.Reshape((28, 28, 1))(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337b8c4-11ae-4ad4-b394-30e981e6b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo Autoencoder\n",
    "autoencoder = tf.keras.Model(encoder_input, decoded)\n",
    "\n",
    "plot_model(autoencoder, to_file='./red_convolucional.png', show_shapes=True, show_layer_names=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d5a85-00fe-4549-8f9f-a3e4226e7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Entrenar el modelo\n",
    "history=autoencoder.fit(x_train, x_train, epochs=5, batch_size=128, shuffle=True, validation_data=(x_test, x_test))\n",
    "\n",
    "#Salvar los pesos del modelo\n",
    "#autoencoder.save_weights('autoencoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1becbc71-b60f-4586-9b49-d4707002ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruir imágenes de prueba\n",
    "decoded_images = autoencoder.predict(x_test)\n",
    "\n",
    "# Mostrar algunas imágenes originales y reconstruidas\n",
    "n = 10  # Número de imágenes a mostrar\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Imagen original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Imagen reconstruida\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_images[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc68266-99ce-4c5a-8c86-877f85df10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
