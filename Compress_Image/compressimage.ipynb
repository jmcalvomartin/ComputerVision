{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Logo.png\" width=\"300\">\n",
    "\n",
    "# Aprendizaje por Imágenes\n",
    "# Comprimir una imagen usando Machine Learning\n",
    "\n",
    "### Profesor: Jorge Calvo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El objetivo de esta actividad es demostrar como cn técicas de **Machine Learning** podemos trabajar con imágenes y reducir el su tamaño gracias a métodos de aprendizaje no supervisado.\n",
    "Para ello hemos usado el método de **K-Means**, un algoritmo de clasificación.\n",
    "\n",
    "### Algoritmo de K-Means \n",
    "\n",
    "* **Procedimiento** <br>\n",
    "Simplemente reducimos el número total de colores utilizados para representar la imagen, y de esta forma permitimos que se necesiten menos memoria (bits) para su almacenaje.\n",
    "Buscamos la similitud entre pixeles por medio de la creación de **clusters**, una vez que tengamos esa cercanía entre colores cambiaremos el color de todo ese cluster tomando como referencia el color del centroide.\n",
    "\n",
    "**Centroide: Pixel central del cluster.**\n",
    "Cargamos las librerias necesarias para la actividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Solo mostrar errores y advertencias críticas\n",
    "\n",
    "# Configurar el crecimiento de memoria en la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "print(\"GPUs disponibles: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "#%matplotlib widget\n",
    "#%matplotlib inline\n",
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos una imagen para realizar la actividad. La imágen se otiene usando la libreria **openCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../images/camion.jpg\")\n",
    "cuadro=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "ax = plt.axes(xticks=[], yticks=[])\n",
    "ax.imshow(cuadro);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la imagen\n",
    "image_path = '../images/camion.jpg'\n",
    "cuadro = plt.imread(image_path)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cuadro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se representa una imagen?\n",
    "Recordamos que las imagenes se representan como matrices de `(alto, ancho, canales)`, donde los valores de los canales son rojo/verde/azul y varían de 0 a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuadro.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, podemos ver este dataset como una nube de puntos tridimensional, donde cada pixel es una instancia.\n",
    "\n",
    "Vamos a normalizar los valores entre 0 y 1 y a convertirlos en `[n_instancias, 3]`. Cada punto de 3 coordenadas se convierte en un valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizamos la imagen para que tenga valores entre 0 y 1\n",
    "data = cuadro / 255.\n",
    "data = data.reshape(cuadro.shape[0] * cuadro.shape[1], 3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la red convolucional\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(3,(3, 3),  activation='relu', padding='same', input_shape=cuadro.shape),\n",
    "    tf.keras.layers.Reshape((cuadro.shape[0]*cuadro.shape[1],3))\n",
    "])\n",
    "plot_model(model, to_file='./red_convolucional.png', show_shapes=True, show_layer_names=True, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la imagen a un tensor de TensorFlow\n",
    "image_tensor = tf.convert_to_tensor(cuadro, dtype=tf.float32)\n",
    "image_tensor = tf.expand_dims(image_tensor, axis=0)  # Agregar una dimensión para el batch\n",
    "data_tf=model.predict(image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf=np.squeeze(data_tf)\n",
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación de los pixeles de nuestra imágen en relación a su color \n",
    "* Usamos cada canal como punto de representación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/Compress Image.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pixels(data, title, colors=None, N=10000):\n",
    "    if colors is None:\n",
    "        colors = data\n",
    "    #print(data)        \n",
    "    #Se crea una instancia de RandomState de NumPy con una semilla de valor 0. \n",
    "    #Esto se utiliza para generar números aleatorios reproducibles en la siguiente línea.\n",
    "    rng = np.random.RandomState(0)\n",
    "    i = rng.permutation(data.shape[0])[:N]\n",
    "    #print(i)\n",
    "    \n",
    "    #Se genera un conjunto de índices aleatorios a partir de la forma de los datos (data) usando la función permutation del objeto RandomState. \n",
    "    #Se selecciona solo un subconjunto de N índices.\n",
    "    colors = colors[i]\n",
    "    R, G, B = data[i].T\n",
    "    #print(colors)\n",
    "    \n",
    "    #print(data[i].T)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    ax[0].scatter(R, G, color=colors, marker='.')\n",
    "    ax[0].set(xlabel='Red', ylabel='Green', xlim=(0, 1), ylim=(0, 1))\n",
    "    ax[0].set_title(\"Relación entre Rojo y Verde 2D\")\n",
    "\n",
    "    ax[1].scatter(R, B, color=colors, marker='.')\n",
    "    ax[1].set(xlabel='Red', ylabel='Blue', xlim=(0, 1), ylim=(0, 1))\n",
    "    ax[1].set_title(\"Relación entre Rojo y Azul 2D\")\n",
    "\n",
    "    fig.suptitle(title, size=20);\n",
    "    \n",
    "    # plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(R, G, B, color=colors, marker='.')\n",
    "    ax.set(xlabel='Red', ylabel='Green', zlabel=\"Blue\")\n",
    "    ax.set_title(\"Relación entre RGB 3D\")\n",
    "    #ax.view_init(30, 85)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pixels(data, title='Espacio latente de los colores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usamos Machine Learning \n",
    "\n",
    "Vamos ahora a reducir de 16 millones de colores a 16.\n",
    "\n",
    "Como se trata de un dataset grande, vamos a usar una variación del k-means llamada **mini-batch k-Means**, que funciona exactamente igual que el k-means pero con mini-batches.\n",
    "\n",
    "Lo que hacemos es utilizar como hiperparametro de KMeans el número de cluster igual 16, porque es el número de colores al cual queremos reducir. Esto significa que todos nuestros pixeles quedrán arupados en 16 grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')  # Fix NumPy issues.\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "clusters=16\n",
    "\n",
    "#Creamos la instancia del algortimo usando los hiperparametros\n",
    "kmeans = MiniBatchKMeans(n_clusters=clusters, random_state=42, batch_size=32)\n",
    "\n",
    "#Entrenamos\n",
    "kmeans.fit(data)\n",
    "\n",
    "#Obtenemos los colores que tienen los centroides\n",
    "new_colors = kmeans.cluster_centers_[kmeans.predict(data)]\n",
    "\n",
    "#Volvemos a visualiar las gráficas pero unicamente pasamos 16 colores de clasificación\n",
    "plot_pixels(data, colors=new_colors, title=\"Reducir espacio latente a \" + str(clusters) + \" colores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar se han reducido los colores a 16, ahora simplemente nos queda reconstruir la imágen y colocar cada pixel en su sitio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuadro_recolored = new_colors.reshape(cuadro.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6), subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "ax[0].imshow(cuadro)\n",
    "ax[0].set_title('Imágen Original', size=16)\n",
    "ax[1].imshow(cuadro_recolored)\n",
    "ax[1].set_title('Imágen en ' + str(clusters) + ' colores', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobamos el espacio que nos ocupa en memoria la nueva imágen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print('Sin comprimir:', sys.getsizeof(cuadro))\n",
    "print('Comprimida:', sys.getsizeof(cuadro_recolored))\n",
    "print('Factor:', sys.getsizeof(cuadro)/sys.getsizeof(cuadro_recolored))\n",
    "\n",
    "print(f\"Es indiscutible que se pierde calidad, pero pensad que acabamos de conseguir comprimir la imagen con un factor de {sys.getsizeof(cuadro)/sys.getsizeof(cuadro_recolored)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Referencias**\n",
    "\n",
    "*   https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
    "*   https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html\n",
    "*   https://www.oreilly.com/learning/an-illustrated-introduction-to-the-t-sne-algorithm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
